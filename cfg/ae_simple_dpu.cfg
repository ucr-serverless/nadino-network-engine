# Copyright 2022 University of California, Riverside
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

name = "Simple two node";

nfs = (
    {
        id = 1;
        name = "frontendservice";
        tenant_id: 0;

        n_threads = 32;

        params = {
            memory_mb = 0;
            sleep_ns = 0;
            compute = 0;
        };

        node = 0;
        // 0 for passive receive, 1 for active generate
        mode = 0;
    },
    {
        id = 2;
        name = "currencyservice";
        tenant_id: 0;

        n_threads = 32;

        params = {
            memory_mb = 0;
            sleep_ns = 0;
            compute = 0;
        };

        node = 1;
        mode = 0;
    }
);

routes = (
    {
        id = 1;
        name = "Route 1";

        hops = [1, 2, 1];
    }
);

nodes = (
    {
        id = 0;
        hostname = "node2.nadino.kkprojects-pg0.clemson.cloudlab.us";
        dpu_hostname = "dpu2"

        ip_address = "10.10.1.6";
        // this is the DPU gateway IP
        dpu_ip_addr = "10.10.1.12"
        // this port is for the control plane socket 
        port = 8084;

        // the rdma deivce on the DPU
        rdma_device = "mlx5_2";
        // the comch server PCIe addr on the DPU
        comch_server_device = "0000:03:00.0";
        // the comch client PCIe addr on the host
        comch_client_device = "0000:81:00.0";
        // the comch client PCIe addr on the host
        comch_client_rep_device = "0000:81:00.0";
        // RDMA device index
        sgid_idx = 1;
        // 0 for spright(does not use RDMA gateway runs on host together with functions)
        // 1 for palladium_host_with_naive_ingress(use RDMA, gateway runs on host, use the default skt ingress)
        // 2 for palladium_host(use RDMA, gateway runs on host, the functions will send packets by itself)
        // 3 for palladium_dpu
        // connect with ing
        // map to p_mode in the code
        mode = 4;
        // 0 for not connect ingress, 1 for connect to nadino ingress
        receive_req = 1;
        mm_ip = "10.10.1.6";
        mm_port = 8087;
    },
    {
        id = 1;
        hostname = "node3.nadino.kkprojects-pg0.clemson.cloudlab.us";
        dpu_hostname = "dpu3";

        ip_address = "10.10.1.8";
        dpu_ip_addr = "10.10.1.13";
        port = 8084;

        rdma_device = "mlx5_2";
        comch_server_device = "0000:03:00.0";
        comch_client_device = "0000:81:00.0";
        comch_client_rep_device = "0000:81:00.0";

        // RDMA device index
        sgid_idx = 1;
        mode = 4;
        // 0 for not connect ingress, 1 for connect to ingress
        receive_req = 0;
        mm_ip = "10.10.1.8";
        mm_port = 8086;
    }
);

// single tenant
tenants = (
    {
        id = 0;
        weight = 5;
        routes = [1, 2, 3, 4, 5];
    }
);

memory_manager = {
    local_mempool_size = 4096;
    port = 8086;
    ip = "10.10.1.6";
    // the device to export memory on the host
    device = "mlx5_2";
    // 1 for mm and gateway on different host, 0 for same host case(palladium mempool)decprecate soon
    is_remote_memory = 0;
};

rdma_settings = {
    // 1: use rdma 0: use tcp socket
    // deprecate soon
    use_rdma = 1;
    // 1: use one-side 0: ues_two-side
    use_one_side = 0;
    // max_rdma_tasks_per_ctx
    n_init_task = 8000;
    n_init_recv_req = 4000;

    tenant_expt = 0;
    msg_sz = 1024;
    n_msg = 2000000;
    // the ip of the ingress socket connection
    // could check it in the ingress log
    // this IP is the remote IP (ingress) that is connecting
    ngx_ip = "10.10.1.4";

    // default ngx id
    // only support one ngx worker now
    ngx_id = 0;
    json_path = "cfg/multi-tenancy-expt.json";
    // if we are using dummy nf, we should use 1, otherwise 0
    is_dummy_nf = 1;
};
